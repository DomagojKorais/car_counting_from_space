{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "import concurrent.futures\n",
    "from itertools import repeat\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=2.0, threshold=0):\n",
    "    \"\"\"Return a sharpened version of the image, using an unsharp mask.\"\"\"\n",
    "    blurred = cv.GaussianBlur(image, kernel_size, sigma)\n",
    "    sharpened = float(amount + 1) * image - float(amount) * blurred\n",
    "    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))\n",
    "    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))\n",
    "    sharpened = sharpened.round().astype(np.uint8)\n",
    "    if threshold > 0:\n",
    "        low_contrast_mask = np.absolute(image - blurred) < threshold\n",
    "        np.copyto(sharpened, image, where=low_contrast_mask)\n",
    "    return sharpened\n",
    "\n",
    "def convert_from_cowc_to_planet(image,alpha = 1.2,beta = -50,small_to_large_image_size_ratio = 0.33,factor=1.3):\n",
    "    '''convert an image from cowc dataset to an image similar to those made by planet satellite.\n",
    "    the original resolution is 15cm, the target resolution is 50cm.\n",
    "    Emulate pansharpening using laplacian unsharp mask, change contrast and brightness.\n",
    "    The optimal values where found by eye, a better solution would automate this step.\n",
    "    In output image a car is 40-50 pixels wide'''\n",
    "    #params\n",
    "    #contrast and brightness\n",
    "    #alpha = 1.2 # Contrast control (1.0-3.0)\n",
    "    #beta = -50 # Brightness control (0-100)\n",
    "    #small_to_large_image_size_ratio = 0.33 #size ratio, that is how much I want to resize the original image\n",
    "    #factor=1.3#how much to enlarge resized image, used to match cars width in pixels, in order for the cnn to perform better on test data\n",
    "    \n",
    "    image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    \n",
    "    small_sharpened_img = cv2.resize(unsharp_mask(image), # original image\n",
    "                           (0,0), # set fx and fy, not the final size\n",
    "                           fx=small_to_large_image_size_ratio, \n",
    "                           fy=small_to_large_image_size_ratio, \n",
    "                           interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    small_sharpened_img = cv2.resize(small_sharpened_img, # original image\n",
    "                           (0,0), # set fx and fy, not the final size\n",
    "                           fx=1/small_to_large_image_size_ratio * factor, \n",
    "                           fy=1/small_to_large_image_size_ratio * factor)\n",
    "    return small_sharpened_img\n",
    "\n",
    "def convert_from_path_and_save(input_path,dest_path,img,**kwargs):\n",
    "    img_path = input_path/img\n",
    "    dest_path = dest_path/img\n",
    "    input_img = cv2.imread(str(img_path))\n",
    "    cv.imwrite(str(dest_path),convert_from_cowc_to_planet(input_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(\"../storage/data/Potsdam_ISPRS/all_data\")\n",
    "output_path = Path(\"../storage/data/Potsdam_ISPRS/all_data_transformed\")\n",
    "imgs = listdir(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds elapsed for 1000 images : 11.770115375518799\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#serial version\n",
    "start = time.time()\n",
    "\n",
    "for img in imgs:\n",
    "    convert_from_path_and_save(input_path,output_path, img)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Seconds elapsed for \" +str(len(imgs)) + \" images : \" + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.01 Âµs\n",
      "Seconds elapsed for 12800 images, parallel version : 188.88276982307434\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "#parallel version (need ssd to improve performance because I/O bounded problem)\n",
    "\n",
    "start = time.time()\n",
    "max_workers=8\n",
    "chunksize = int(len(imgs)/max_workers)\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "    executor.map(convert_from_path_and_save, repeat(input_path), repeat(output_path), imgs, chunksize=chunksize)\n",
    "\n",
    "            \n",
    "end = time.time()\n",
    "print(\"Seconds elapsed for \" +str(len(imgs)) + \" images, parallel version : \" + str(end - start))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
